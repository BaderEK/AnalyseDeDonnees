{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://polytech.univ-lyon1.fr/uas/polytech/LOGO/UDL_logo_blanc-01%20(2).png\" alt=\"drawing\" style=\"width:100px;\"/></center>\n",
    "\n",
    "# Introduction à Python pour la Data Science\n",
    "\n",
    "## Analyse en Composantes Principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction\n",
    "### 1.1 `Scikit-learn` *vs.*  R\n",
    "L'objectif de ce tutoriel est d'introduire l'utilisation de la librairie `scikit-learn` de Python pour l'exploration de données multidimensionnelles. Seule l'utilisation directe des fonctions d'exploration est abordée. Se pose rapidement une question: quand utiliser `scikit-learn` de Python plutôt que R plus complet et plus simple d'emploi?\n",
    "\n",
    "- Préférer R et ses libraires si la **présentation graphique** des résultats et leur **interprétation** est prioritaire.\n",
    "- Pour l'emploi de méthodes (analyse factorielle discriminante, canonique, positionnement multidimensionnel...) pas codées en Python.\n",
    "- Préférer Python et `scikit-learn` pour mettre au point une chaîne de traitements (*pipe line*) opérationnelle de l'extraction à une analyse privilégiant la prévision brute à l'interprétation et pour des données quantitatives ou rendues quantitatives (\"vectorisation\" de corpus de textes).\n",
    "\n",
    "### 1.2 Fonctions de `scikit-learn`\n",
    "La communauté qui développe cette librairie est très active, elle évolue rapidement.  Ne pas hésiter à consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) pour des compléments. Voici une sélection de ses principales fonctionnalités.\n",
    "- Transformations (standardisation, discrétisation binaire, regroupement de modalités, imputations rudimentaires de données manquantes) , \"vectorisation\" de corpus de textes (encodage, catalogue, Tf-idf), images.\n",
    "- Exploration: ACP, classification non supervisée (mélanges gaussiens, propagation d'affinité, ascendante hiérarchique, SOM,...). Une fonction est aojutée pour l'Analyse des Correspondances.\n",
    "- Modélisation et apprentissage, voir le dépôt correspondant.\n",
    "\n",
    "\n",
    "### 1.3 ACP avec `scikit-learn`\n",
    "L'objectif est d'illustrer la mise en oeuvre de l'analyse en composantes principales. Consulter la [documentation](http://scikit-learn.org/stable/user_guide.html) et ses nombreux [exemples](http://scikit-learn.org/stable/auto_examples/index.html) pour plus de détails sur l'utilisation de `scikit-learn`. \n",
    "\n",
    "La librairie `scikit-learn` a principalement été conçu en vue de l'analyse de signaux. Aussi, de nombreuses options de l'ACP ne sont pas disponibles, notamment les graphiques usuels (biplot, cercle des corrélations...). En revanche des résultats sont liés à la version probabiliste de l'ACP sous hypothèse d'une distribution gaussienne multidimensionnelle des données. \n",
    "\n",
    "**Attention**, l'ACP est centrée mais par réduite. L'option n'est pas prévue et les variables doivent être réduites (fonction `sklearn.preprocessing.scale`) avant si c'est nécessaire. L'attribut `transform` désigne les composantes principales, sous-entendu: transformation par réduction de la dimension; `n_components` fixe le nombre de composantes retenues, par défaut toutes; l'attribut `components_` contient les `n_components` vecteurs propres mais non normalisés, c'est-à-dire de norme carrée la valeur propre associée, et donc à utiliser pour représenter les variables.\n",
    "\n",
    "D'autres versions d'analyse en composantes principales sont proposées dans `Scikit-learn`: *kernel PCA, sparse PCA, ICA*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chargement de la première feuille de données\n",
    "X = pd.read_excel(\"../99 - Datasets/autos.xlsx\",sheet_name=0,header=0,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un code propre est un code commenté. C'est pourquoi il est intéressant de commenter les différentes étapes importantes comme ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18, 6)\n",
      "                  CYL  PUISS  LONG  LARG  POIDS  V_MAX\n",
      "Modele                                                \n",
      "Alfasud TI       1350     79   393   161    870    165\n",
      "Audi 100         1588     85   468   177   1110    160\n",
      "Simca 1300       1294     68   424   168   1050    152\n",
      "Citroen GS Club  1222     59   412   161    930    151\n",
      "Fiat 132         1585     98   439   164   1105    165\n",
      "Lancia Beta      1297     82   429   169   1080    160\n",
      "Peugeot 504      1796     79   449   169   1160    154\n",
      "Renault 16 TL    1565     55   424   163   1010    140\n",
      "Renault 30       2664    128   452   173   1320    180\n",
      "Toyota Corolla   1166     55   399   157    815    140\n",
      "Alfetta-1.66     1570    109   428   162   1060    175\n",
      "Princess-1800    1798     82   445   172   1160    158\n",
      "Datsun-200L      1998    115   469   169   1370    160\n",
      "Taunus-2000      1993     98   438   170   1080    167\n",
      "Rancho           1442     80   431   166   1129    144\n",
      "Mazda-9295       1769     83   440   165   1095    165\n",
      "Opel-Rekord      1979    100   459   173   1120    173\n",
      "Lada-1300        1294     68   404   161    955    140\n"
     ]
    }
   ],
   "source": [
    "#dimension\n",
    "print(X.shape)\n",
    "\n",
    "#nombre d'observations\n",
    "n = X.shape[0]\n",
    "\n",
    "#nombre de variables\n",
    "p = X.shape[1]\n",
    "\n",
    "#affichage du dataset\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But du TP\n",
    "Vous trouverez ci-dessous des cellules de code de l'analyse en composantes principales du dataset. Je vais vous demander de commenter chaque cellule comme je l'ai fait au-dessus. Quand un graphe ou un tableau sort d'une éxecution, je vous demande également de commenter le résulat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = sc.fit_transform(X)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(Z,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.std(Z,axis=0,ddof=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acp = PCA(svd_solver='full')\n",
    "print(acp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord = acp.fit_transform(Z)\n",
    "print(acp.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acp.explained_variance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval = (n-1)/n*acp.explained_variance_\n",
    "print(eigval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acp.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,p+1),eigval)\n",
    "plt.title(\"Scree plot\")\n",
    "plt.ylabel(\"Eigen values\")\n",
    "plt.xlabel(\"Factor number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,p+1),np.cumsum(acp.explained_variance_ratio_))\n",
    "plt.title(\"Explained variance vs. # of factors\")\n",
    "plt.ylabel(\"Cumsum explained variance ratio\")\n",
    "plt.xlabel(\"Factor number\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 1/np.arange(p,0,-1)\n",
    "bs = np.cumsum(bs)\n",
    "bs = bs[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'Val.Propre':eigval,'Seuils':bs}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = pd.DataFrame(coord,index=X.index,columns=np.arange(1,p+1))\n",
    "print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(12,12))\n",
    "axes.set_xlim(-6,6)\n",
    "axes.set_ylim(-6,6)\n",
    "for i in range(n):\n",
    "    plt.annotate(X.index[i],(coord[i,0],coord[i,1]))\n",
    "plt.plot([-6,6],[0,0],color='silver',linestyle='-',linewidth=1)\n",
    "plt.plot([0,0],[-6,6],color='silver',linestyle='-',linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = np.sum(Z**2,axis=1)\n",
    "print(pd.DataFrame({'ID':X.index,'d_i':di}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos2 = coord**2\n",
    "for j in range(p):\n",
    "    cos2[:,j] = cos2[:,j]/di\n",
    "    \n",
    "print(pd.DataFrame({'id':X.index,'COS2_1':cos2[:,0],'COS2_2':cos2[:,1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = coord**2\n",
    "for j in range(p):\n",
    "    ctr[:,j] = ctr[:,j]/(n*eigval[j])\n",
    "    \n",
    "print(pd.DataFrame({'id':X.index,'CTR_1':ctr[:,0],'CTR_2':ctr[:,1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(ctr,axis=0))\n",
    "print(acp.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_eigval = np.sqrt(eigval)\n",
    "corvar = np.zeros((p,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(p):\n",
    "    corvar[:,k] = acp.components_[k,:] * sqrt_eigval[k]\n",
    "print(corvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'id':X.columns,'COR_1':corvar[:,0],'COR_2':corvar[:,1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(8,8))\n",
    "axes.set_xlim(-1,1)\n",
    "axes.set_ylim(-1,1)\n",
    "\n",
    "for j in range(p):\n",
    "    plt.annotate(X.columns[j],(corvar[j,0],corvar[j,1]))\n",
    "    \n",
    "plt.plot([-1,1],[0,0],color='silver',linestyle='-',linewidth=1)\n",
    "plt.plot([0,0],[-1,1],color='silver',linestyle='-',linewidth=1)\n",
    "\n",
    "cercle = plt.Circle((0,0),1,color='blue',fill=False)\n",
    "axes.add_artist(cercle)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donner les interprétations des graphes suivants :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosinus carré des variables\n",
    "cos2var = corvar**2\n",
    "print(pd.DataFrame({'id':X.columns,'COS2_1':cos2var[:,0],'COS2_2':cos2var[:,1]}))\n",
    "\n",
    "#vérification de la théorie\n",
    "print(np.sum(cos2var,axis=1))\n",
    "\n",
    "#contributions\n",
    "ctrvar = cos2var\n",
    "\n",
    "for k in range(p):\n",
    "    ctrvar[:,k] = ctrvar[:,k]/eigval[k]\n",
    "\n",
    "#on n'affiche que pour les deux premiers axes\n",
    "print(pd.DataFrame({'id':X.columns,'CTR_1':ctrvar[:,0],'CTR_2':ctrvar[:,1]}))\n",
    "\n",
    "#ici, on peut vérifier\n",
    "print(np.sum(ctrvar,axis=0))\n",
    "\n",
    "#chargement des individus supplémentaires\n",
    "indSupp = pd.read_excel(\"../99 - Datasets/autos.xlsx\",sheet_name=1,header=0,index_col=0)\n",
    "print(indSupp)\n",
    "\n",
    "#centrage-réduction avec les paramètres des individus actifs\n",
    "ZIndSupp = sc.transform(indSupp)\n",
    "print(ZIndSupp)\n",
    "\n",
    "#projection dans l'espace factoriel\n",
    "coordSupp = acp.transform(ZIndSupp)\n",
    "print(coordSupp)\n",
    "\n",
    "#positionnement des individus supplémentaires dans le premier plan\n",
    "fig, axes = plt.subplots(figsize=(12,12))\n",
    "axes.set_xlim(-6,6)\n",
    "axes.set_ylim(-6,6)\n",
    "\n",
    "for i in range(n):\n",
    "    plt.annotate(X.index[i],(coord[i,0],coord[i,1]))\n",
    "    \n",
    "for i in range(coordSupp.shape[0]):\n",
    "    plt.annotate(indSupp.index[i],(coordSupp[i,0],coordSupp[i,1]),color='b')\n",
    "    \n",
    "#ajouter les axes\n",
    "plt.plot([-6,6],[0,0],color='silver',linestyle='-',linewidth=1)\n",
    "plt.plot([0,0],[-6,6],color='silver',linestyle='-',linewidth=1)\n",
    "\n",
    "#affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation des variables supplémentaires\n",
    "varSupp = pd.read_excel(\"../99 - Datasets/autos.xlsx\",sheet_name=2,header=0,index_col=0)\n",
    "print(varSupp)\n",
    "\n",
    "#variables supplémentaires quanti\n",
    "vsQuanti = varSupp.iloc[:,:2].values\n",
    "print(vsQuanti)\n",
    "\n",
    "#corrélation avec les axes factoriels\n",
    "corSupp = np.zeros((vsQuanti.shape[1],p))\n",
    "\n",
    "for k in range(p):\n",
    "    for j in range(vsQuanti.shape[1]):\n",
    "        corSupp[j,k] = np.corrcoef(vsQuanti[:,j],coord[:,k])[0,1]\n",
    "        \n",
    "#affichage des corrélations avec les axes\n",
    "print(corSupp)\n",
    "\n",
    "#cercle des corrélations avec les var. supp\n",
    "fig, axes = plt.subplots(figsize=(8,8))\n",
    "axes.set_xlim(-1,1)\n",
    "axes.set_ylim(-1,1)\n",
    "\n",
    "for j in range(p):\n",
    "    plt.annotate(X.columns[j],(corvar[j,0],corvar[j,1]))\n",
    "    \n",
    "for j in range(vsQuanti.shape[1]):\n",
    "    plt.annotate(varSupp.columns[j],(corSupp[j,0],corSupp[j,1]),color='g')\n",
    "    \n",
    "#ajouter les axes\n",
    "plt.plot([-1,1],[0,0],color='silver',linestyle='-',linewidth=1)\n",
    "plt.plot([0,0],[-1,1],color='silver',linestyle='-',linewidth=1)\n",
    "\n",
    "#ajouter un cercle\n",
    "cercle = plt.Circle((0,0),1,color='blue',fill=False)\n",
    "axes.add_artist(cercle)\n",
    "\n",
    "#affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#traitement de var. quali supplementaire\n",
    "vsQuali = varSupp.iloc[:,2]\n",
    "print(vsQuali)\n",
    "\n",
    "#modalités de la variable qualitative\n",
    "modalites = np.unique(vsQuali)\n",
    "print(modalites)\n",
    "\n",
    "#liste des couleurs\n",
    "couleurs = ['r','g','b']\n",
    "\n",
    "#faire un graphique en coloriant les points\n",
    "fig, axes = plt.subplots(figsize=(12,12))\n",
    "axes.set_xlim(-6,6)\n",
    "axes.set_ylim(-6,6)\n",
    "\n",
    "#pour chaque modalité de la var. illustrative\n",
    "for c in range(len(modalites)):\n",
    "    #numéro des individus concernés\n",
    "    numero = np.where(vsQuali == modalites[c])\n",
    "    \n",
    "    #les passer en revue pour affichage\n",
    "    for i in numero[0]:\n",
    "        plt.annotate(X.index[i],(coord[i,0],coord[i,1]),color=couleurs[c])\n",
    "    \n",
    "#ajouter les axes\n",
    "plt.plot([-6,6],[0,0],color='silver',linestyle='-',linewidth=1)\n",
    "plt.plot([0,0],[-6,6],color='silver',linestyle='-',linewidth=1)\n",
    "\n",
    "#affichage\n",
    "plt.show()\n",
    "\n",
    "#structure intermédiaire\n",
    "df = pd.DataFrame({'Finition':vsQuali,'F1':coord[:,0],'F2':coord[:,1]})\n",
    "\n",
    "#puis calculer les moyennes conditionnelles\n",
    "print(df.pivot_table(index='Finition',values=['F1','F2'],aggfunc=pd.Series.mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enseignant\n",
    "Patrice Mazel - patrice.mazel@protonmail.com - 3A MAM 2021/2022"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "interpreter": {
   "hash": "ee153b6a0713fdd39ba181897152c41db5f6b59d99688239508a213ad48a6d8d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "nav_menu": {
    "height": "512px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": "10",
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
